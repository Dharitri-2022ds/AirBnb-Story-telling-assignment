{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dharitri-2022ds/AirBnb-Story-telling-assignment/blob/main/Module_6_Mid_Course_Assignment_ML_Case_Study(Telecom_Customer_Churn_Prediction).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n",
        "## **TELECOM CUSTOMER CHURN PREDICTION ðŸ“ˆ**"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member Name**- Dharitri\n",
        "\n",
        "#### **What is Customer Churn?**\n",
        "\n",
        "Customer churn is defined as when customers or subscribers discontinue doing business with a firm or service.\n",
        "\n",
        "Customers in the telecom industry can choose from a variety of service providers and actively switch from one to the next. The telecommunications business has an annual churn rate of 15-25 percent in this highly competitive market.\n",
        "\n",
        "Individualized customer retention is tough because most firms have a large number of customers and can't afford to devote much time to each of them. The costs would be too great, outweighing the additional revenue. However, if a corporation could forecast which customers are likely to leave ahead of time, it could focus customer retention efforts only on these \"high risk\" clients. The ultimate goal is to expand its coverage area and retrieve more customers loyalty. The core to succeed in this market lies in the customer itself.\n",
        "\n",
        "Customer churn is a critical metric because it is much less expensive to retain existing customers than it is to acquire new customers.\n",
        "\n",
        "\n",
        "**To reduce customer churn, telecom companies need to predict which customers are at high risk of churn.**\n",
        "\n",
        "To detect early signs of potential churn, one must first develop a holistic view of the customers and their interactions across numerous channels, including store/branch visits, product purchase histories, customer service calls, Web-based transactions, and social media interactions, to mention a few.\n",
        "As a result, by addressing churn, these businesses may not only preserve their market position, but also grow and thrive. More customers they have in their network, the lower the cost of initiation and the larger the profit. As a result, the company's key focus for success is reducing client attrition and implementing effective retention strategy.\n",
        "\n",
        "**Objectives:**\n",
        "\n",
        " I will explore the data and try to answer some questions like:\n",
        "\n",
        "- What's the % of Churn Customers and customers that keep in with the active services?\n",
        "- Is there any patterns in Churn Customers based on the gender?\n",
        "- Is there any patterns/preference in Churn Customers based on the type of service provided?\n",
        "- What's the most profitable service types?\n",
        "- Which features and services are most profitable?\n",
        "- Many more questions that will arise during the analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Telecom Churn Analysis and Prediction**\n",
        "\n",
        "The Telecom Churn Analysis and Prediction project delves into a dataset containing customer attributes and churn status within the telecommunications industry. Its primary objective is to analyze key insights and patterns to understand customer behavior and predict churn.\n",
        "\n",
        "The project begins with a comprehensive exploration of the dataset, comprising customer characteristics such as gender, tenure, services subscribed, payment methods, and churn status. Notably, the data exhibits high quality, with minimal missing values.\n",
        "\n",
        "Insights gleaned from the analysis shed light on various aspects, including customer tenure and its correlation with churn, the impact of monthly charges on churn rates, and the significance of certain features in predicting churn.\n",
        "\n",
        "To address the challenge of imbalanced data, the project employs advanced machine learning techniques, training and evaluating multiple classifiers. The Random Forest Classifier using SMOTEENN emerges as the top-performing model, achieving an accuracy of 93.16% and demonstrating notable improvements in recall, precision, and F1-score for churned customers.\n",
        "\n",
        "Looking ahead, the project underscores the significance of its findings for strategic decision-making in customer retention and churn reduction efforts within the telecommunications sector. It emphasizes the potential for real-time churn prediction and proactive intervention strategies to enhance customer loyalty and drive sustainable growth.\n",
        "\n",
        "In conclusion, the Telecom Churn Analysis and Prediction project offers valuable insights and predictive capabilities to empower telecommunications companies in optimizing operations, enhancing customer satisfaction, and fostering competitiveness in the marketplace.\n",
        "\n",
        "Source of the dataset : https://www.kaggle.com/blastchar/telco-customer-churn ( IBM Sample dataset)"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary Libraries\n",
        "import numpy as np  # Library for numerical operations\n",
        "import pandas as pd  # Library for data manipulation and analysis\n",
        "import seaborn as sns  # Library for data visualization based on matplotlib\n",
        "import matplotlib.ticker as mtick  # Library for formatting plot ticks\n",
        "import matplotlib.pyplot as plt  # Library for creating visualizations\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn import metrics  # Library for evaluating the performance of machine learning models\n",
        "from sklearn.model_selection import train_test_split  # Library for splitting data into training and testing sets\n",
        "from sklearn.metrics import recall_score  # Function to calculate the recall score\n",
        "from sklearn.metrics import classification_report  # Function to generate a classification report\n",
        "from sklearn.metrics import confusion_matrix  # Function to create a confusion matrix\n",
        "from sklearn.tree import DecisionTreeClassifier  # Decision tree classifier\n",
        "from sklearn.ensemble import RandomForestClassifier  # Random forest classifier\n",
        "from imblearn.combine import SMOTEENN  # Library for combining over- and under-sampling using SMOTE and Edited Nearest Neighbors\n",
        "from sklearn.decomposition import PCA  # Principal Component Analysis for dimensionality reduction"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "#Mount google drive for accessing the dataset Telecom Customer Churn Prediction\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#File path of Telecom Customer Churn Prediction dataset in google drive\n",
        "#drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/WA_Fn-UseC_-Telco-Customer-Churn.csv\"\n",
        "\n",
        "Telco_df = pd.read_csv(file_path,encoding='latin-1')"
      ],
      "metadata": {
        "id": "z4ZiHQLZrcpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "# Display the first five rows\n",
        "Telco_df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# Display the number of rows and columns\n",
        "Telco_df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of rows: 7043\n",
        "\n",
        "Number of columns: 21"
      ],
      "metadata": {
        "id": "xc1dk1DIu8H1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking all the features\n",
        "Telco_df.columns"
      ],
      "metadata": {
        "id": "NMMoc-dxxhfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the data types of all the columns\n",
        "Telco_df.dtypes"
      ],
      "metadata": {
        "id": "_yS9qQo0xsQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the descriptive statistics of numeric variables\n",
        "Telco_df.describe()"
      ],
      "metadata": {
        "id": "OapEUE3HyUM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- SeniorCitizen is actually a categorical hence the 25%-50%-75% distribution is not proper\n",
        "\n",
        "- 75% customers have tenure less than 55 months\n",
        "\n",
        "- Average Monthly charges are USD 64.76 whereas 25% customers pay more than USD 89.85 per month"
      ],
      "metadata": {
        "id": "-3Se1Y32yl5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a horizontal bar chart to display the count of 'Churn' values\n",
        "Telco_df['Churn'].value_counts().plot(kind='barh', figsize=(6, 4))\n",
        "plt.xlabel(\"Count\", labelpad=14)  # Set label for the x-axis\n",
        "plt.ylabel(\"Target Variable\", labelpad=14)  # Set label for the y-axis\n",
        "plt.title(\"Count of TARGET Variable per category\", y=1.02)  # Set the title of the plot\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "1wOWeIrOy0ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the percentage of each 'Churn' category\n",
        "100 * Telco_df['Churn'].value_counts() / len(Telco_df['Churn'])"
      ],
      "metadata": {
        "id": "ow6B8ozPy_lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the count of each category in the 'Churn' column\n",
        "Telco_df['Churn'].value_counts()"
      ],
      "metadata": {
        "id": "CBHY4ibhzQvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data is highly imbalanced, ratio = 73:27\n",
        "\n",
        "So we analyse the data with other features while taking the target values separately to get some insights."
      ],
      "metadata": {
        "id": "TQhuT7Jj0tYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###** Dataset Information**"
      ],
      "metadata": {
        "id": "0n6bmu0000RI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Display the information about the dataset\n",
        "Telco_df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Display the number of duplicate values\n",
        "Telco_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Display the number of missing values\n",
        "Telco_df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(Telco_df.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we don't have any missing data."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "Telco_df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning"
      ],
      "metadata": {
        "id": "M8g4Lty0qH9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Total Charges should be numeric amount. Let's convert it to numerical data type\n",
        "Telco_df.TotalCharges = pd.to_numeric(Telco_df.TotalCharges, errors='coerce')\n",
        "\n",
        "# Output the count of missing values in each column\n",
        "Telco_df.isnull().sum()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " We can see there are 11 missing values in TotalCharges column.\n",
        "\n",
        " Let's check these records"
      ],
      "metadata": {
        "id": "kOiE7ejEpGtG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Locate rows where the 'TotalCharges' column is null\n",
        "Telco_df.loc[Telco_df['TotalCharges'].isnull() == True]"
      ],
      "metadata": {
        "id": "dpjSjWXfpYnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Value Treatment"
      ],
      "metadata": {
        "id": "jNVbiWhVpthQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the % of these records compared to total dataset is very low ie 0.15%, it is safe to ignore them from further processing."
      ],
      "metadata": {
        "id": "ZGs-aoIfq8A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing missing values\n",
        "Telco_df.dropna(how = 'any', inplace = True)"
      ],
      "metadata": {
        "id": "k75rLxl4p6tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide customers into bins based on tenure e.g. for tenure < 12 months: assign a tenure group if 1-12, for tenure between 1 to 2 Yrs, tenure group of 13-24; so on..."
      ],
      "metadata": {
        "id": "pPKFFjf7rR1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the max tenure\n",
        "print(Telco_df['tenure'].max()) #72"
      ],
      "metadata": {
        "id": "Zcx4pNeHrVPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the tenure in bins of 12 months\n",
        "labels = [\"{0} - {1}\".format(i, i + 11) for i in range(1, 72, 12)]\n",
        "\n",
        "Telco_df['tenure_group'] = pd.cut(Telco_df.tenure, range(1, 80, 12), right=False, labels=labels)"
      ],
      "metadata": {
        "id": "zYnVfh_drtRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Telco_df['tenure_group'].value_counts()"
      ],
      "metadata": {
        "id": "dAqqOwIRsBCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove columns not required for processing"
      ],
      "metadata": {
        "id": "MY9Hsr3VsNAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop column customerID and tenure\n",
        "Telco_df.drop(columns= ['customerID','tenure'], axis=1, inplace=True)\n",
        "Telco_df.head()"
      ],
      "metadata": {
        "id": "ewd9LQugsP-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***3. Data Exploration***\n",
        "\n",
        "1. Plot distibution of individual predictors by churn"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univariate Analysis"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through predictors and create count plots for each\n",
        "for i, predictor in enumerate(Telco_df.drop(columns=['Churn', 'TotalCharges', 'MonthlyCharges'])):\n",
        "    plt.figure(i)  # Create a new figure\n",
        "    sns.countplot(data=Telco_df, x=predictor, hue='Churn')  # Create a count plot for the predictor with respect to 'Churn'"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Convert the target variable 'Churn' in a binary numeric variable i.e. Yes=1 ; No = 0\n"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Telco_df['Churn'] = np.where(Telco_df.Churn == 'Yes',1,0)"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Telco_df.head()"
      ],
      "metadata": {
        "id": "tu7ECmY1ulRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Convert all the categorical variables into dummy variables"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy variables for categorical columns in telco_data and convert to integer type\n",
        "Telco_df_dummies = pd.get_dummies(Telco_df).astype(int)\n",
        "\n",
        "# Display the first few rows of the modified DataFrame\n",
        "Telco_df_dummies.head()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Relationship between Monthly Charges and Total Charges"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot using seaborn to visualize the relationship between 'MonthlyCharges' and 'TotalCharges'\n",
        "sns.lmplot(data=Telco_df_dummies, x='MonthlyCharges', y='TotalCharges', fit_reg=False)\n",
        "plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Total Charges increase as Monthly Charges increase - as expected."
      ],
      "metadata": {
        "id": "5ogZ173VvqyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Churn by Monthly Charges and Total Charges"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a kernel density plot to compare monthly charges for churned and non-churned customers\n",
        "Mth = sns.kdeplot(Telco_df_dummies.MonthlyCharges[(Telco_df_dummies[\"Churn\"] == 0)], color=\"Red\", shade=True)\n",
        "Mth = sns.kdeplot(Telco_df_dummies.MonthlyCharges[(Telco_df_dummies[\"Churn\"] == 1)], ax=Mth, color=\"Blue\", shade=True)\n",
        "\n",
        "# Set legend, y-axis label, x-axis label, and title for the plot\n",
        "Mth.legend([\"No Churn\", \"Churn\"], loc='upper right')\n",
        "Mth.set_ylabel('Density')\n",
        "Mth.set_xlabel('Monthly Charges')\n",
        "Mth.set_title('Monthly charges by churn')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insight:** Churn is high when Monthly Charges are high."
      ],
      "metadata": {
        "id": "8fsK9qyinBkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a kernel density plot to compare total charges for churned and non-churned customers\n",
        "Tot = sns.kdeplot(Telco_df_dummies.TotalCharges[(Telco_df_dummies[\"Churn\"] == 0)], color=\"Red\", shade=True)\n",
        "Tot = sns.kdeplot(Telco_df_dummies.TotalCharges[(Telco_df_dummies[\"Churn\"] == 1)], ax=Tot, color=\"Blue\", shade=True)\n",
        "\n",
        "# Set legend, y-axis label, x-axis label, and title for the plot\n",
        "Tot.legend([\"No Churn\", \"Churn\"], loc='upper right')\n",
        "Tot.set_ylabel('Density')\n",
        "Tot.set_xlabel('Total Charges')\n",
        "Tot.set_title('Total charges by churn')"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Surprising insight** as higher Churn at lower Total Charges\n",
        "\n",
        "However if we combine the insights of 3 parameters i.e. Tenure, Monthly Charges & Total Charges then the picture is bit clear :- Higher Monthly Charge at lower tenure results into lower Total Charge.\n",
        "\n",
        "**Hence, all these 3 factors viz Higher Monthly Charge, Lower tenure and Lower Total Charge are linked to High Churn.**"
      ],
      "metadata": {
        "id": "JtwGVN23nzQR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  **Build a correlation of all predictors with 'Churn'**"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size for the correlation plot\n",
        "plt.figure(figsize=(20, 8))\n",
        "\n",
        "# Plot the correlation of each feature with 'Churn' in a bar chart\n",
        "Telco_df_dummies.corr()['Churn'].sort_values(ascending=False).plot(kind='bar')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "HIGH Churn seen in case of Month to month contracts, No online security, No Tech support, First year of subscription and Fibre Optics Internet\n",
        "\n",
        "LOW Churn is seens in case of Long term contracts, Subscriptions without internet service and The customers engaged for 5+ years\n",
        "\n",
        "Factors like Gender, Availability of PhoneService and # of multiple lines have alomost NO impact on Churn\n",
        "\n",
        "This is also evident from the Heatmap below"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size for the heatmap\n",
        "plt.figure(figsize=(30, 25))\n",
        "\n",
        "# Create a heatmap to visualize the correlation matrix of Telco_df_dummies\n",
        "sns.heatmap(Telco_df_dummies.corr(), annot=True, cmap=\"viridis\")\n",
        "\n",
        "# Display the heatmap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Bp5WKWIcpMSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Bivariate Analysis"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame for non-churned and churned customers\n",
        "new_df1_target0 = Telco_df.loc[Telco_df[\"Churn\"] == 0]\n",
        "new_df1_target1 = Telco_df.loc[Telco_df[\"Churn\"] == 1]"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def uniplot(df, col, title, hue=None):\n",
        "    sns.set_style('whitegrid')  # Set the plot style\n",
        "    sns.set_context('talk')  # Set the context for the plot\n",
        "    plt.rcParams[\"axes.labelsize\"] = 20  # Set the label size for the axes\n",
        "    plt.rcParams['axes.titlesize'] = 22  # Set the title size for the axes\n",
        "    plt.rcParams['axes.titlepad'] = 30  # Set the title padding for the axes\n",
        "\n",
        "    temp = pd.Series(data=hue)\n",
        "    fig, ax = plt.subplots()\n",
        "    fig.set_size_inches(10, 6)  # Set a smaller size for the plot\n",
        "    plt.xticks(rotation=45)  # Rotate x-axis labels for better visibility\n",
        "    plt.title(title)  # Set the title of the plot\n",
        "    ax = sns.countplot(data=df, x=col, order=df[col].value_counts().index, hue=hue, palette='bright')  # Create a count plot\n",
        "\n",
        "    plt.yscale('log')  # Set y-axis scale to logarithmic\n",
        "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: '{:g}'.format(y)))  # Set y-axis formatter\n",
        "    plt.show()  # Display the plot"
      ],
      "metadata": {
        "id": "--H_wbznqA8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of gender for churned customers based on the 'Partner' column\n",
        "uniplot(new_df1_target1, col='Partner', title='Distribution of Gender for Churned Customers', hue='gender')"
      ],
      "metadata": {
        "id": "8ij5Li8xqRwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of gender for non-churned customers based on the 'Partner' column\n",
        "uniplot(new_df1_target0, col='Partner', title='Distribution of Gender for Non Churned Customers', hue='gender')"
      ],
      "metadata": {
        "id": "j83wbb1EqgFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of payment methods for churned customers based on the 'PaymentMethod' column\n",
        "uniplot(new_df1_target1, col='PaymentMethod', title='Distribution of PaymentMethod for Churned Customers', hue='gender')"
      ],
      "metadata": {
        "id": "7OKHh2IuqswJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of contract types for churned customers based on the 'Contract' column\n",
        "uniplot(new_df1_target1, col='Contract', title='Distribution of Contract for Churned Customers', hue='gender')"
      ],
      "metadata": {
        "id": "FwvWvcpfq5FQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of tech support for churned customers based on the 'TechSupport' column\n",
        "uniplot(new_df1_target1, col='TechSupport', title='Distribution of TechSupport for Churned Customers', hue='gender')"
      ],
      "metadata": {
        "id": "6L9NVGaHrLiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a count plot to visualize the distribution of senior citizens among churned customers based on the 'SeniorCitizen' column\n",
        "uniplot(new_df1_target1, col='SeniorCitizen', title='Distribution of SeniorCitizen for Churned Customers', hue='gender')"
      ],
      "metadata": {
        "id": "LlixD0bPrXBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These are some of the quick insights from this exercise:\n",
        "\n",
        "- Electronic check medium are the highest churners\n",
        "- Contract Type - Monthly customers are more likely to churn because of no contract terms, as they are free to go customers.\n",
        "- No Online security, No Tech Support category are high churners\n",
        "- Non senior Citizens are high churners\n",
        "\n",
        "Note: There could be many more such insights, so take this as an assignment and try to get more insights :)"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the dataframe\n",
        "telco_df = Telco_df_dummies.copy()"
      ],
      "metadata": {
        "id": "roUlSDRHshIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top rows of the dataframe\n",
        "telco_df.head()"
      ],
      "metadata": {
        "id": "1Xy2qM33spuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the features to X and the target variable to y\n",
        "X = telco_df.drop('Churn', axis=1)\n",
        "y = telco_df['Churn']\n",
        "\n",
        "# Output the shape of X and the count of each category in y\n",
        "print('X:', X.shape)\n",
        "print('y:', y.value_counts())"
      ],
      "metadata": {
        "id": "myX2a8sRsxrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train Test Split"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Output the shapes of Xtrain and Xtest, and the count of each category in ytrain and ytest\n",
        "print('Xtrain:', Xtrain.shape)\n",
        "print('Xtest:', Xtest.shape)\n",
        "print('ytrain:', ytrain.value_counts())\n",
        "print('ytest:', ytest.value_counts())"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree Classifier"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Decision Tree model with specified parameters\n",
        "model_dt = DecisionTreeClassifier(criterion=\"gini\", random_state=100, max_depth=6, min_samples_leaf=8)"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "model_dt.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "njUTNXGmts9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the y value\n",
        "y_pred = model_dt.predict(Xtest)"
      ],
      "metadata": {
        "id": "Uua4xdmityt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy score of the decision tree model using the test data\n",
        "model_dt.score(Xtest, ytest)"
      ],
      "metadata": {
        "id": "SKXBa1h2uABZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the classification report for the test set using the predicted values and true values, specifying the labels\n",
        "print(classification_report(ytest, y_pred, labels=[0, 1]))"
      ],
      "metadata": {
        "id": "OPBvxZGyuKE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see that the accuracy is quite low, and as it's an imbalanced dataset, we shouldn't consider Accuracy as our metrics to measure the model, as Accuracy is cursed in imbalanced datasets.\n",
        "\n",
        "Hence, we need to check recall, precision & f1 score for the minority class, and it's quite evident that the precision, recall & f1 score is too low for Class 1, i.e. churned customers.\n",
        "\n",
        "Hence, moving ahead to call SMOTEENN (UpSampling + ENN)"
      ],
      "metadata": {
        "id": "9vVGu1ABuSXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTEENN()\n",
        "\n",
        "# Resample the dataset using SMOTEENN to address class imbalance\n",
        "X_resampled, y_resampled = sm.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "s13vLkZJuhho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the resampled data into training and testing sets\n",
        "xr_train, xr_test, yr_train, yr_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "k1P-EQyou5Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a decision tree classifier with specified parameters\n",
        "model_dt_smote = DecisionTreeClassifier(criterion=\"gini\", random_state=100, max_depth=6, min_samples_leaf=8)"
      ],
      "metadata": {
        "id": "SopAsL_hvGSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the decision tree model to the resampled training data\n",
        "model_dt_smote.fit(xr_train, yr_train)\n",
        "\n",
        "# Make predictions using the model\n",
        "yr_predict = model_dt_smote.predict(xr_test)\n",
        "\n",
        "# Calculate the accuracy score of the model\n",
        "model_score_r = model_dt_smote.score(xr_test, yr_test)\n",
        "\n",
        "# Output the accuracy score and the classification report\n",
        "print(model_score_r)\n",
        "print(metrics.classification_report(yr_test, yr_predict))"
      ],
      "metadata": {
        "id": "sIzhZ4xRvIf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the confusion matrix\n",
        "print(metrics.confusion_matrix(yr_test, yr_predict))"
      ],
      "metadata": {
        "id": "vbXpWInBvWPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can see quite better results, i.e. Accuracy: 95 %, and a very good recall, precision & f1 score for minority class.\n",
        "\n",
        "Let's try with some other classifier."
      ],
      "metadata": {
        "id": "AmDc1syVw0Gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest Classifier"
      ],
      "metadata": {
        "id": "ux61cvfRxDQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random forest classifier with specified parameters\n",
        "model_rf = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)"
      ],
      "metadata": {
        "id": "dLv6HLTXw-ZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the random forest model\n",
        "model_rf.fit(Xtrain, ytrain)"
      ],
      "metadata": {
        "id": "Y065ap1qxKoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using the random forest model\n",
        "y_pred = model_rf.predict(Xtest)"
      ],
      "metadata": {
        "id": "BBExq1eNxUjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf.score(Xtest, ytest)"
      ],
      "metadata": {
        "id": "UzyMpt5uxcZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(ytest, y_pred, labels=[0,1]))"
      ],
      "metadata": {
        "id": "YBAK952WxjxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sm = SMOTEENN()\n",
        "\n",
        "# Resample the dataset using SMOTEENN to address class imbalance\n",
        "X_resampled1, y_resampled1 = sm.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "b39i2PZMxslb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the resampled data into training and testing sets\n",
        "xr_train1, xr_test1, yr_train1, yr_test1 = train_test_split(X_resampled1, y_resampled1, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "YKJid6OAx5Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random forest classifier with specified parameters\n",
        "model_rf_smote = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)"
      ],
      "metadata": {
        "id": "JBrRqFirx7Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the random forest model using the resampled training data\n",
        "model_rf_smote.fit(xr_train1, yr_train1)"
      ],
      "metadata": {
        "id": "F4hF4nG3yE-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions using the random forest model\n",
        "yr_predict1 = model_rf_smote.predict(xr_test1)"
      ],
      "metadata": {
        "id": "0tZS22q4yMmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_score_r1 = model_rf_smote.score(xr_test1, yr_test1)"
      ],
      "metadata": {
        "id": "3v3I6Y52yPW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the accuracy score and the classification report\n",
        "print(model_score_r1)\n",
        "print(metrics.classification_report(yr_test1, yr_predict1))"
      ],
      "metadata": {
        "id": "Dz5h2KnAydN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output the confusion matrix\n",
        "print(metrics.confusion_matrix(yr_test1, yr_predict1))"
      ],
      "metadata": {
        "id": "QQgLsa4XykLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With RF Classifier also we are able to get quite good results, infact better than Decision Tree."
      ],
      "metadata": {
        "id": "4ptpKxEGyrJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performing PCA"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying PCA\n",
        "pca = PCA(0.9)\n",
        "xr_train_pca = pca.fit_transform(xr_train1)\n",
        "xr_test_pca = pca.transform(xr_test1)\n",
        "explained_variance = pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random forest classifier with specified parameters\n",
        "model = RandomForestClassifier(n_estimators=100, criterion='gini', random_state=100, max_depth=6, min_samples_leaf=8)"
      ],
      "metadata": {
        "id": "GHVxacy-zP_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the Model\n",
        "model.fit(xr_train_pca, yr_train1)"
      ],
      "metadata": {
        "id": "h_RBE404zSBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yr_predict_pca = model.predict(xr_test_pca)"
      ],
      "metadata": {
        "id": "E8HCz5HTzbPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy score of the model using the test data\n",
        "model_score_r_pca = model.score(xr_test_pca, yr_test1)\n",
        "\n",
        "# Output the accuracy score and the classification report\n",
        "print(model_score_r_pca)\n",
        "print(metrics.classification_report(yr_test1, yr_predict_pca))"
      ],
      "metadata": {
        "id": "azaVDdhAzdH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With PCA, we couldn't see any better results, hence let's finalise the model which was created by RF Classifier, and save the model so that we can use it in a later stage :)"
      ],
      "metadata": {
        "id": "uW4WTQMfz2Fd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pickling the model"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'model.sav'\n",
        "pickle.dump(model_rf_smote, open(filename, 'wb')) # Save the model to a file using pickle"
      ],
      "metadata": {
        "id": "weXf7aK10JpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model from the file using pickle\n",
        "load_model = pickle.load(open(filename, 'rb'))"
      ],
      "metadata": {
        "id": "nVBqmOap0aYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_score_r1 = load_model.score(xr_test1, yr_test1)\n",
        "model_score_r1"
      ],
      "metadata": {
        "id": "K-W0entX0jn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our final model i.e. RF Classifier with SMOTEENN, is now ready and dumped in model.sav, which we will use and prepare API's so that we can access our model from UI."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  RANDOM FOREST OUTPERFORMED OTHER MODELS\n",
        "\n",
        "MOST IMPORTANT FEATURES ARE\n",
        "\n",
        "  -- CONTRACT\n",
        "\n",
        "  --  MONTHLY CHARGE\n",
        "  \n",
        "  -- TENURE IN MONTHS\n",
        "  \n",
        "  -- NUMBER OF REFERRALS\n",
        "  \n",
        "  -- NUMBER OF INDEPENDENTS"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "The Telecom Customer Churn Prediction project aimed to uncover key insights from a dataset containing customer attributes and churn status. Through a systematic exploration and analysis of the data, several significant findings were revealed, contributing to a deeper understanding of customer behavior and churn dynamics in the telecommunications industry.\n",
        "\n",
        "**Data Overview and Quality**\n",
        "\n",
        "The dataset comprised 7043 entries and 21 columns, encompassing various customer characteristics such as gender, tenure, services subscribed, payment methods, and churn status. Notably, the data exhibited high quality, with no missing values except for a negligible proportion in the 'TotalCharges' column.\n",
        "\n",
        "**Key Insights**\n",
        "\n",
        " - Customer Tenure: Analysis showed that a substantial majority of customers had a tenure of less than 55 months, indicating a relatively high turnover rate among newer subscribers.\n",
        "\n",
        " - Monthly Charges and Churn: There was a discernible correlation between higher monthly charges and churn, suggesting that customers with elevated billing amounts were more prone to churn.\n",
        "\n",
        " - Imbalanced Data: The dataset presented a significant class imbalance, with churned customers comprising only 27% of the total, necessitating specialized handling during model training and evaluation.\n",
        "\n",
        " - Feature Importance: Exploration of predictor variables revealed several critical insights. Notably, month-to-month contracts, absence of online security and tech support, and shorter subscription durations were associated with higher churn rates.\n",
        "\n",
        "**Model Performance and Evaluation**\n",
        "\n",
        "Multiple machine learning classifiers were trained and evaluated, with the Random Forest Classifier using SMOTEENN emerging as the top-performing model. This model achieved an accuracy of 93.16% and exhibited substantial improvements in recall, precision, and F1-score for churned customers.\n",
        "\n",
        "**Future Directions**\n",
        "\n",
        "The insights gained from this analysis have significant implications for strategic decision-making in customer retention and churn reduction efforts within the telecommunications sector. Future endeavors may involve deploying the trained model for real-time churn prediction, enabling proactive intervention strategies and targeted marketing campaigns to mitigate churn and enhance customer loyalty.\n",
        "\n",
        "***Conclusion***\n",
        "\n",
        "In conclusion, the Telecom Customer Churn Prediction project provided valuable insights into the factors influencing customer churn and laid the groundwork for data-driven strategies to improve customer retention and business performance. By leveraging advanced analytics and machine learning techniques, telecommunications companies can optimize their operations and enhance customer satisfaction, ultimately driving sustainable growth and competitiveness in the dynamic marketplace."
      ],
      "metadata": {
        "id": "xNNRKa8D1wo3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Case Study !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}